---
title: "SQL: Exercises"
format:
  html: default
execute:
  echo: true
  warning: false
  message: false
editor_options:
  chunk_output_type: inline
---
  
You can download this .qmd file from [here](https://github.com/proback/264_fall_2024/blob/main/16_SQL_exercises.qmd).  Just hit the Download Raw File button.

The code in [15_SQL.qmd](https://github.com/proback/264_fall_2024/blob/main/SQL_code/15_SQL.qmd) walked us through many of the examples in MDSR Chapter 15; now, we present a set of practice exercises in converting from the tidyverse to SQL.

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(mdsr)
library(dbplyr)
library(DBI)
```

```{r}
#| eval: FALSE

# connect to the database which lives on a remote server maintained by
#   St. Olaf's IT department
library(RMariaDB)
con <- dbConnect(
  MariaDB(), host = "mdb.stolaf.edu",
  user = "ruser", password = "ruserpass", 
  dbname = "flight_data"
)
```


## On Your Own - Extended Example from MDSR

Refer to [Section 15.5](https://mdsr-book.github.io/mdsr3e/15-sqlI.html#sec-ft8-flights) in MDSR, where they attempt to replicate some of FiveThirtyEight's analyses.  The MDSR authors provide a mix of SQL and R code to perform their analyses, but the code will not work if you simply cut-and-paste as-is into R.  Your task is to convert the book code into something that actually runs, and then *apply it to data from 2024*.  Very little of the code needs to be adjusted; it mostly needs to be repackaged.

Hints:

- use `dbGetQuery()`
- note that what they call `carrier` is just called `Reporting_Airline` in the `flightdata` table; you don't have to merge in a `carrier` table, although it's unfortunate that the `Reporting_Airline` codes are a bit cryptic


1. Below Figure 15.1, the MDSR authors first describe how to plot slowest and fastest airports.  Instead of using *target time*, which has a complex definition, we will use *arrival time*, which oversimplifies the situation but gets us in the ballpark.  Duplicate the equivalent of the table below for 2024 using the code in MDSR:

```{r}
#| eval: FALSE

# A tibble: 30 × 3
   dest  avgDepartDelay avgArrivalDelay
   <chr>          <dbl>           <dbl>
 1 ORD            14.3            13.1 
 2 MDW            12.8             7.40
 3 DEN            11.3             7.60
 4 IAD            11.3             7.45
 5 HOU            11.3             8.07
 6 DFW            10.7             9.00
 7 BWI            10.2             6.04
 8 BNA             9.47            8.94
 9 EWR             8.70            9.61
10 IAH             8.41            6.75
# 20 more rows
```


2. Following the table above, the MDSR authors mimic one more FiveThirtyEight table which ranks carriers by time added vs. typical and time added vs. target.  In this case, we will find average arrival delay after controlling for the routes flown.  Again, duplicate the equivalent of the table below for 2024 using the code in MDSR:

```{r}
#| eval: FALSE

# A tibble: 14 × 5
   carrier carrier_name                numRoutes numFlights wAvgDelay
   <chr>   <chr>                           <int>      <dbl>     <dbl>
 1 VX      Virgin America                     72      57510   -2.69  
 2 FL      AirTran Airways Corporation       170      79495   -1.55  
 3 AS      Alaska Airlines Inc.              242     160257   -1.44  
 4 US      US Airways Inc.                   378     414665   -1.31  
 5 DL      Delta Air Lines Inc.              900     800375   -1.01  
 6 UA      United Air Lines Inc.             621     493528   -0.982 
 7 MQ      Envoy Air                         442     392701   -0.455 
 8 AA      American Airlines Inc.            390     537697   -0.0340
 9 HA      Hawaiian Airlines Inc.             56      74732    0.272 
10 OO      SkyWest Airlines Inc.            1250     613030    0.358 
11 B6      JetBlue Airways                   316     249693    0.767 
12 EV      ExpressJet Airlines Inc.         1534     686021    0.845 
13 WN      Southwest Airlines Co.           1284    1174633    1.13  
14 F9      Frontier Airlines Inc.            326      85474    2.29  
```


## On Your Own - Adapting 164 Code

These problems are based on class exercises from SDS 164, so you've already solved them in R!  Now we're going to try to duplicate those solutions in SQL (but with 2023 data instead of 2013).

```{r}
# Read in 2013 NYC flights data
library(nycflights13)
flights_nyc13 <- nycflights13::flights
planes_nyc13 <- nycflights13::planes
```


1. Summarize carriers flying to MSP by number of flights and proportion that are cancelled (assuming that a missing arrival time indicates a cancelled flight).  [This was #4 in 17_longer_pipelines.Rmd.]

```{r}
# Original solution from SDS 164
flights_nyc13 |>
  mutate(carrier = fct_collapse(carrier, "Delta +" = c("DL", "9E"), 
                                      "American +"= c("AA", "MQ"), 
                                     "United +" = c("EV", "OO", "UA"))) |>
  filter(dest == "MSP") |>   
  group_by(origin, carrier) |>
  summarize(n_flights = n(), 
            num_cancelled = sum(is.na(arr_time)),
            prop_cancelled = mean(is.na(arr_time)))
```

First duplicate the output above, then check trends in 2023 across all origins.  Here are a few hints:

- use flightdata instead of flights_nyc13
- remember that flights_nyc13 only contained 2013 and 3 NYC origin airports (EWR, JFK, LGA)
- is.na can be replaced with CASE WHEN ArrTime IS NULL THEN 1 ELSE 0 END or with CASE WHEN cancelled = 1 THEN 1 ELSE 0 END
- CASE WHEN can also be used replace fct_collapse

```{sql, connection = con}
SELECT origin,
  CASE WHEN Reporting_Airline IN ("DL", "9E") THEN 'Delta +'
    WHEN Reporting_Airline IN ("AA", "MQ") THEN 'American +'
    WHEN Reporting_Airline IN ("EV", "OO", "UA") THEN 'United +'
    ELSE 'Other' END AS new_carrier,
  SUM(1) AS n_flights,
  SUM(cancelled) AS n_cancelled,
  AVG(cancelled) AS prop_cancelled,
  year
FROM flightdata
WHERE dest = 'MSP' AND origin IN ('JFK', 'EWR', 'LGA') AND year = 2023
GROUP BY origin, new_carrier
LIMIT 1, 10;

```

2. Plot number of flights vs. proportion cancelled for every origin-destination pair (assuming that a missing arrival time indicates a cancelled flight).  [This was #7 in 17_longer_pipelines.Rmd.]

```{r}
# Original solution from SDS 164
flights_nyc13 |>
  group_by(origin, dest) |>
  summarize(n = n(),
            prop_cancelled = mean(is.na(arr_time))) |>
  filter(prop_cancelled < 1) |>
  ggplot(aes(n, prop_cancelled)) + 
  geom_point()
```

First duplicate the plot above for 2023 data, then check trends across all origins.  Do all of the data wrangling in SQL.  Here are a few hints:

- use flightdata instead of flights_nyc13
- remember that flights_nyc13 only contained 2013 and 3 NYC origin airports (EWR, JFK, LGA)
- use an `sql` chunk and an `r` chunk
- include `connection = ` and `output.var = ` in your sql chunk header (this doesn't seem to work with dbGetQuery()...)


```{sql, connection = con, output.var = tester}
SELECT 
  origin, dest,
  SUM(1) AS count,
  AVG(cancelled) AS prop_cancelled
FROM flightdata
WHERE origin = 'JFK' OR origin = 'EWR' OR origin = 'LGA' AND year = 2013
GROUP BY origin, dest
HAVING prop_cancelled < 1;
```

```{r}
tester |>
  ggplot(aes(count, prop_cancelled)) + 
  geom_point()
```

3. [SKIP until the planes dataset becomes available] Produce a table of weighted plane age by carrier, where weights are based on number of flights per plane.  [This was #6 in 26_more_joins.Rmd.]

```{r}
# Original solution from SDS 164
flights_nyc13 |>
  left_join(planes_nyc13, join_by(tailnum)) |>
  mutate(plane_age = 2013 - year.y) |>
  group_by(carrier) |>
  summarize(unique_planes = n_distinct(tailnum),
            mean_weighted_age = mean(plane_age, na.rm =TRUE),
            sd_weighted_age = sd(plane_age, na.rm =TRUE)) |>
  arrange(mean_weighted_age)
```

First duplicate the output above for 2023, then check trends across all origins.  Do all of the data wrangling in SQL.  Here are a few hints:

- use flightdata instead of flights_nyc13
- remember that flights_nyc13 only contained 2013 and 3 NYC origin airports (EWR, JFK, LGA)
- you'll have to merge the flights dataset with the planes dataset *when it becomes available*
- you can use DISTINCT inside a COUNT()


## On Your Own - Noninvasive Auditory Diagnostic Tools

You will use SQL to query the [Wideband Acoustic Immittance (WAI) Database](https://www.science.smith.edu/wai-database/) hosted by Smith College.  WAI measurements are being developed as noninvasive auditory diagnostic tools for people of all ages, and the WAI Database hosts WAI ear measurements that have been published in peer-review articles.  The goal of the database is to "enable auditory researchers to share WAI measurements and combine analyses over multiple datasets."

You have two primary goals:

1) duplicate Figure 1 from a [2019 manuscript](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7093226/) by Susan Voss.  You will need to query the WAI Database to build a dataset which you can pipe into `ggplot()` to recreate Figure 1 *as closely as possible*.

2) Find a study where subjects of different sex, race, ethnicity, or age groups were enrolled, and produce plots of frequency vs. mean absorption by group.

You should be using JOINs in both (1) and (2).

**Hints:**

- Parse the caption from Figure 1 carefully to determine how mean absorbances are calculated: "Mean absorbances for the 12 studies within the WAI database as of July 1, 2019. Noted in the legend are the peer-reviewed publications associated with the datasets, the number of individual ears, and the equipment used in the study. When multiple measurements were made on the same ear, the average from those measurements was used in the calculation across subjects for a given study. Some subjects have measurements on both a right and a left ear, and some subjects have measurements from only one ear; this figure includes every ear in the database and does not control for the effect of number of ears from each subject."
- filter for only the 12 studies shown in Figure 1 (and also for frequencies shown in Figure 1)
- study the patterns of frequencies.  It seems that most researchers used the same set of frequencies for each subject, ear, and session.
- note the scale of the x-axis
- the key labels contain AuthorsShortList, Year, and Instrument, in addition to the number of unique ears (I think Werner's N may be incorrect?)

**Starter Code:**

```{r}
#| eval: FALSE

library(tidyverse)
library(mdsr)
library(dbplyr)
library(DBI)

library(RMariaDB)
con <- dbConnect(
  MariaDB(), host = "scidb.smith.edu",
  user = "waiuser", password = "smith_waiDB", 
  dbname = "wai"
)
Measurements <- tbl(con, "Measurements")
PI_Info <- tbl(con, "PI_Info")
Subjects <- tbl(con, "Subjects")

# collect(Measurements)
```

Run the following queries in a chunk with {sql, connection = con}:

- SHOW TABLES;
- DESCRIBE Measurements;
- SELECT * FROM PI_Info LIMIT 0,1;

