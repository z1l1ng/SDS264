---
title: "Strings: HW"
author: "Ziling Zhen"
format:
  pdf: default
editor_options: 
  chunk_output_type: console
---

## 11_strings_part2.qmd: Exercises #1-17

```{r, echo = FALSE}
library(tidyverse)
library(rvest)
library(httr)

#spotify <- read_csv("Data/spotify.csv") 
spotify <- read_csv("https://proback.github.io/264_fall_2024/Data/spotify.csv")

spot_smaller <- spotify |>
  select(
    title, 
    artist, 
    album_release_date, 
    album_name, 
    subgenre, 
    playlist_name
  )

spot_smaller <- spot_smaller[c(5, 32, 49, 52, 83, 175, 219, 231, 246, 265), ]
spot_smaller
```

1. Identify the input type and output type for each of these examples:

```{r}
#1
str_view(spot_smaller$subgenre, "pop")
typeof(str_view(spot_smaller$subgenre, "pop"))
class(str_view(spot_smaller$subgenre, "pop"))

#2
#str_view(spot_smaller$subgenre, "pop", match = NA)
#str_view(spot_smaller$subgenre, "pop", html = TRUE)

#3
str_subset(spot_smaller$subgenre, "pop")

#4
str_detect(spot_smaller$subgenre, "pop")
```

>> 1) input: a vector of 10 strings, output: view of the strings with "pop"
2) input: a vector of 10 strings, output: view of the strings with "pop" and the ones without
3) input: a vector of 10 strings, output: 5 vectors with "pop"
4) input: a vector of 10 strings, output: trues or falses for if our string contains "pop"

2. Use str_detect to print the rows of the spot_smaller tibble containing songs that have "pop" in the subgenre. (i.e. make a new tibble with fewer rows)

```{r}
spot_even_smaller <- spot_smaller |>
  mutate(sub_pop = str_detect(subgenre, "pop"))

spot_even_smaller |>
  filter(sub_pop)
```


3. Find the mean song title length for songs with "pop" in the subgenre and songs without "pop" in the subgenre.  

```{r}
spot_even_smaller |>
  mutate(title_length = str_length(title)) |>
  group_by(sub_pop) |>
  summarize(mean_title_length = mean(title_length))

spot_even_smaller |>
  mutate(title_length = str_length(title)) |>
  group_by(sub_pop) |>
  summarize(mean_title_length = mean(title_length)) |>
  mutate(sub_pop = ifelse(sub_pop,"Genre with pop", "Genre without pop"))
```


Producing a table like this would be great:

# A tibble: 2 × 2
  sub_pop mean_title_length
  <lgl>               <dbl>
1 FALSE                18.6
2 TRUE                 13.6

Producing a table like this would be SUPER great (hint: ifelse()):

# A tibble: 2 × 2
  sub_pop           mean_title_length
  <chr>                         <dbl>
1 Genre with pop                 13.6
2 Genre without pop              18.6


4. In the bigspotify dataset, find the proportion of songs which contain "love" in the title (track_name) by playlist_genre.

```{r}
bigspotify <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv')

bigspotify
```

```{r}
bigspotify |>
  mutate(haslove = str_detect(track_name, "love")) |>
  group_by(playlist_genre) |>
  summarise(prop_love = mean(haslove, na.rm = TRUE))
```


## Matching patterns with regular expressions

^abc   string starts with abc
abc$   string ends with abc
.      any character
[abc]  a or b or c
[^abc] anything EXCEPT a or b or c


5. Given the corpus of common words in stringr::words, create regular expressions that find all words that:

- Start with “y”.
- End with “x”
- Are exactly three letters long.
- Have seven letters or more.
- Start with a vowel.
- End with ed, but not with eed.
- Words where q is not followed by u. (are there any in `words`?)

```{r}
# Try using str_view() or str_subset()

# For example, to find words with "tion" at any point, I could use:
#str_view(words, "tion")
str_subset(words, "tion")

#Start with “y”
str_subset(words, "^y")

#End with “x”
str_subset(words, "x$")

#Are exactly three letters long
str_subset(words, "^[A-Za-z]{3}$") 
#OR
#str_subset(words, "^...$")

# Have seven letters or more.
str_subset(words, "^.......") 
#OR
#str_subset(words, "^.{7}") 

#Start with a vowel.
str_subset(words, "^[aeiou]")

#End with ed, but not with eed
str_subset(words, "[^e]ed$")

#Words where q is not followed by u
str_subset(words, "q[^u]")
```


## More useful regular expressions: 

\\d  - any number
\\s  - any space, tab, etc
\\b  - any boundary: space, ., etc.

Here are the regular expression special characters that require an escape character (a preceding \ ): \ ^ $ . ? * | + ( ) [ {

For any characters with special properties, use \ to "escape" its special meaning ... but \ is itself a special character ... so we need two \\!  (e.g. \\$, \\., etc.)

```{r}
#str_view(spot_smaller$title, "$")
#str_view(spot_smaller$title, "\\$")
```


6. In bigspotify, how many track_names include a $?  Be sure you print the track_names you find and make sure the dollar sign is not just in a featured artist!

```{r}
bigspotify |>
  filter(str_detect(track_name, "\\$")) |>
  #filter(!str_detect(track_name,"\\(.*\\$.*\\)")) |>
  filter(!str_detect(track_name, "(feat|with).*\\$")) |>
  select(track_name, track_artist) |>
  print(n = Inf)
```


7. In bigspotify, how many track_names include a dollar amount (a $ followed by a number).

```{r}
bigspotify |>
  filter(str_detect(track_name, "\\$\\d")) |>
  filter(!str_detect(track_name, "(feat|with).*\\$")) |>
  select(track_name, track_artist) |>
  print(n = Inf)
```

OR

```{r}
bigspotify |>
    filter(str_detect(track_name, "\\$\\d")) |>
    select(track_name, track_artist)
```


## Repetition

?  0 or 1 times
+  1 or more
*  0 or more
{n} exactly n times
{n,} n or more times
{,m} at most m times
{n,m} between n and m times
? or 

```{r}
str_subset(spot_smaller$album_name, "[A-Z]{2,}")

str_subset(spot_smaller$album_release_date, "\\d{4}-\\d{2}")
```


**Use at least 1 repetition symbol when solving 8-10 below**

8. Modify the first regular expression above to also pick up "m.A.A.d" (in addition to "BEYONC" and "II").  That is, pick up strings where there might be a period between capital letters.

```{r}
str_subset(spot_smaller$album_name, "[A-Z?.A-Z]{2,}")

str_subset(spot_smaller$album_name, "[A-Z?.]{2,}")
```

9. Create some strings that satisfy these regular expressions and explain.

- "^.*$" 
this can be any expression

- "\\{.+\\}"
this contains curly brackets with 1 or more things in it

```{r}
str_detect("", "^.*$")
str_detect("m,y", "^.*$")
str_detect("97^7hf", "^.*$")
str_detect(")9nfud%{}", "^.*$")
str_detect("n 09", "^.*$")

str_detect("{tfvb0987}", "\\{.+\\}")
str_detect("{ziling zhen}", "\\{.+\\}")
str_detect("{Z}", "\\{.+\\}")
str_detect("{ }", "\\{.+\\}")
```



10. Create regular expressions to find all `stringr::words` that:

- Start with three consonants.
- Have two or more vowel-consonant pairs in a row.

```{r}
#consonant
str_subset(words, "^[^aeiouy]{3,}")
```
OR
```{r}
#consonant
words |>
  as_tibble() |>
  filter(str_detect(value, "^[^aeiouy]{3,}"))
```

```{r}
#vowel-consonant pairs
str_subset(words, "([aeiouy][^aeiouy]){2,}")
```

## Useful functions for handling patterns

str_extract() : extract a string that matches a pattern
str_count() : count how many times a pattern occurs within a string


```{r}
str_extract(spot_smaller$album_release_date, "\\d{4}-\\d{2}")

spot_smaller |>
  select(album_release_date) |>
  mutate(year_month = str_extract(album_release_date, "\\d{4}-\\d{2}"))


spot_smaller |>
  select(artist) |>
  mutate(n_vowels = str_count(artist, "[aeiou]"))
```


11. In the spot_smaller dataset, how many words are in each title? (hint \\b)

```{r}
spot_smaller |>
  select(title) |>
  mutate(n_words = str_count(title, "\\b[^ ]+\\b"))

str_subset(spot_smaller$title, "\\b[^ ]+\\b")
```



12. In the spot_smaller dataset, extract the first word from every title. Show how you would print out these words as a vector and how you would create a new column on the spot_smaller tibble.  That is, produce this:

```{r}
# [1] "Hear"      "Run"       "Formation" "7/11"      "My"        "It's"     
# [7] "Poetic"    "A.D.H.D"   "Ya"        "Runnin"   
```
Then this:
```{r}
# A tibble: 10 × 2
#   title                                             first_word
#   <chr>                                             <chr>     
# 1 Hear Me Now                                       Hear      
# 2 Run the World (Girls)                             Run       
# 3 Formation                                         Formation 
# 4 7/11                                              7/11      
# 5 My Oh My (feat. DaBaby)                           My        
# 6 It's Automatic                                    It's      
# 7 Poetic Justice                                    Poetic    
# 8 A.D.H.D                                           A.D.H.D   
# 9 Ya Estuvo                                         Ya        
#10 Runnin (with A$AP Rocky, A$AP Ferg & Nicki Minaj) Runnin    
```

```{r}
# "^[^ ]+" all non spaces until first space
spot_smaller |>
  select(title) |>
  mutate(first_word = str_extract(title, "^[^ ]+"))

spot_smaller |>
  select(title) |>
  mutate(first_word = str_extract(title, "^[^ ]+")) |>
  pull(first_word)
```

OR

```{r}
spot_smaller |>
  select(title) |>
  mutate(first_word = str_extract(title, "\\b[^ ]+\\b"))

spot_smaller |>
  select(title) |>
  mutate(first_word = str_extract(title, "\\b[^ ]+\\b")) |>
  pull(first_word)
```

OR

```{r}
str_extract(spot_smaller$title, "^[^ ]+\\b")
```


13. Which decades are popular for playlist_names? Using the bigspotify dataset, try doing each of these steps one at a time!

 - filter the bigspotify dataset to only include playlists that include something like "80's" or "00's" in their title.
 - create a new column that extracts the decade
 - use count to find how many playlists include each decade
 - what if you include both "80's" and "80s"? 
 - how can you count "80's" and "80s" together in your final tibble?
 
```{r}
bigspotify |>
  filter(str_detect(playlist_name, "[0-9]{2}('?)s")) |> # or \\d\\d('?)s
  mutate(decade = str_extract(playlist_name, "[0-9]{2}('?)s")) |>
  select(playlist_name, decade) |>
  filter(decade != "08's") |>
  mutate(decade = str_replace(decade, "'", "")) |>
  count(decade) 
```
 


## Grouping and backreferences

```{r}
# find all fruits with repeated pair of letters.  
fruit = stringr::fruit
fruit
str_view(fruit, "(..)\\1", match = TRUE)

# why does the code below add "pepper" and even "nectarine"?
str_view(fruit, "(..)(.*)\\1", match = TRUE)
```

Tips with backreference: 
- You must use () around the the thing you want to reference.
- To backreference multiple times, use \\1 again.
- The number refers to which spot you are referencing... e.g. \\2 references the second set of () 

```{r}
x1 <- c("abxyba", "abccba", "xyaayx", "abxyab", "abcabc")
str_subset(x1, "(.)(.)(..)\\2\\1")
str_subset(x1, "(.)(.)(..)\\1\\2")
str_subset(x1, "(.)(.)(.)\\1\\2\\3")
```


14. Describe to your groupmates what these expressions will match, and provide a word or expression as an example:

- (.)\\1\\1
>> any string with the same 3 characters, ex. 333, bbb, lll

```{r}
str_detect("o328fjknttt890bjfe", "(.)\\1\\1")
str_detect("ppp", "(.)\\1\\1")
```


- "(.)(.)(.).*\\3\\2\\1"
>> strings 3 characters where they appear in reverse order later in the word

```{r}
str_detect("cbef789dfgnfdj987", "(.)(.)(.).*\\3\\2\\1")
str_detect("iuencm14lkwejrc41mfhiuwer", "(.)(.)(.).*\\3\\2\\1")
str_detect("bbyybb", "(.)(.)(.).*\\3\\2\\1")
```


Which words in `stringr::words` match each expression?

```{r}
str_subset(words, "(.)\\1\\1")

str_subset(words, "(.)(.)(.).*\\3\\2\\1")
```


15. Construct a regular expression to match words in `stringr::words` that contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice) but *not* match repeated pairs of numbers (e.g. 507-786-3861).

```{r}
str_subset(words, "([a-z]{2}).*\\1")

str_detect("507-786-7861", "([a-z]{2}).*\\1")
```


16. Reformat the album_release_date variable in spot_smaller so that it is MM-DD-YYYY instead of YYYY-MM-DD.  (Hint: str_replace().)

```{r}
spot_smaller |>
  mutate(release_date = str_replace(album_release_date, "(\\d{4})-(\\d{2})-(\\d{2})", "\\2-\\3-\\1")) |>
  select(album_release_date, release_date)
```


17. BEFORE RUNNING IT, explain to your partner(s) what the following R chunk will do:

```{r}
sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>% 
  head(5)
```

>> This is going to swap the second and third word in our sentences.

## 12_strings_part3.qmd : On Your Own #1-9.

## On Your Own - Extra practice with strings and regular expressions

1. Describe the equivalents of ?, +, * in {m,n} form.

`?` makes a pattern optional (i.e. it matches 0 or 1 times), so in {m,n} form it would be represented as {0, 1}

`+` lets a pattern repeat (i.e. it matches at least once), so in {m,n} form it would be represented {1, }

`*` lets a pattern be optional or repeats, so in {m,n} form it would be represented as {0, }

2. Describe, in words, what the expression "(.)(.)\\2\\1" will match, and provide a word or expression as an example.

>> The expression "(.)(.)\\2\\1" would match any 2 character, digit, or special character and then those 2 characters, digit, or special character in reverse order, with nothing in between. The \\2 is saying take look for whatever is in our second set of parentheses and \\1 is saying whatever is in our first set of parentheses. 

```{r}
# an & na
str_detect("anna", "(.)(.)\\2\\1")

# %0 & 0%
str_detect("yhbfvh%00%", "(.)(.)\\2\\1")

#  il & li
str_detect("millionaire", "(.)(.)\\2\\1")
```


3. Produce an R string which the regular expression represented by "\\..\\..\\.." matches.  In other words, find a string `y` below that produces a TRUE in `str_detect`.

>> This regular expression is looking for a . represented by \\. followed by any character, digit, or special character, then another . represented by \\. followed by any character, digit, or special character and then another . represented by \\. followed by any character, digit, or special character, thus giving it the form ".z.z.z" where z can be any character, digit, or special character. Note: the string doesn't have to be by itself.


```{r}
str_detect("tyu iny^.^.0.E..  ... .....", "\\..\\..\\..")

str_detect("ziling.....zhen", "\\..\\..\\..")

str_detect(".a.b.c", "\\..\\..\\..")
```

4. Solve with `str_subset()`, using the words from `stringr::words`:

- Find all words that start or end with x.
```{r}
str_subset(words, "^x|x$")
```

- Find all words that start with a vowel and end with a consonant.
```{r}
str_subset(words, "^[aieou].*[^aieou]$")
```

- Find all words that start and end with the same letter
```{r}
str_subset(words, "^(.).*\\1$")
```

5. What words in `stringr::words` have the highest number of vowels? What words have the highest proportion of vowels? (Hint: what is the denominator?)  Figure this out using the tidyverse and piping, starting with `as_tibble(words) |>`.

```{r}
# most vowels
as_tibble(words) |>
  mutate(n_vowels = str_count(value, "[aieou]")) |>
  arrange(desc(n_vowels))

# proportion of vowels
as_tibble(words) |>
  mutate(n_vowels = str_count(value, "[aieou]"),
         word_length = str_length(value),
         prop_vowels = n_vowels/word_length) |>
  arrange(desc(prop_vowels))
```


6. From the Harvard sentences data, use `str_extract` to produce a tibble with 3 columns:  the sentence, the first word in the sentence, and the first word ending in "ed" (NA if there isn't one).

```{r}
as_tibble(sentences) |>
  mutate(first_word = str_extract(value, "^[^ ]+\\b"),
         first_word_ed = str_extract(value, "\\b\\w*ed\\b"))

# str_view(sentences, "\\b\\w*ed\\b")
# "^[^ ]+\\b" first word
```



7. Find and output all contractions (words with apostrophes) in the Harvard sentences, assuming no sentence has multiple contractions.

```{r}
as_tibble(sentences) |>
  mutate(contractions = str_extract(value, "\\w*'\\w\\b")) |>
  filter(contractions != is.na(NA))
```

>> This prints out all the words with apostrophes in the Harvard sentences, note that words like store's, mans's, king's, queen's, etc are showing up as well.

8. *Carefully* explain what the code below does, both line by line and in general terms.

```{r}
temp <- str_replace_all(words, "^([A-Za-z])(.*)([a-z])$", "\\3\\2\\1")
as_tibble(words) |>
  semi_join(as_tibble(temp)) |>
  print(n = Inf)
```

>> The first line, assigns a vector to "temp" of our words in which we use str_replace to change them a little. In our str_replace we are saying the first set of parenthesis is the starting letter, the second set of parentheses is anything of any length (the letters in between the starting letter and the last letter) so this will go to our last set of parentheses which is the last letter, and for our replace we are saying last parentheses, second parentheses, then first parentheses, so we now have words in the form where it starts with the letter it ends with and ends with the letter it starts with. In line 2 we are taking a words and turning it into a tibble, then keeping all the words that are also in our temp vector. We then print all these words. Now, we have a list of words in which if you swap the first and last letter they are still a word, including words that start and end with the same letter. 

## Coco and Rotten Tomatoes

We will check out the Rotten Tomatoes page for the 2017 movie Coco, scrape information from that page (we'll get into web scraping in a few weeks!), clean it up into a usable format, and answer some questions using strings and regular expressions.

```{r}
# used to work
# coco <- read_html("https://www.rottentomatoes.com/m/coco_2017")

robotstxt::paths_allowed("https://www.rottentomatoes.com/m/coco_2017")

library(polite)
coco <- "https://www.rottentomatoes.com/m/coco_2017" |>
  bow() |> 
  scrape()

top_reviews <- 
  "https://www.rottentomatoes.com/m/coco_2017/reviews?type=top_critics" |> 
  bow() |> 
  scrape()
top_reviews <- html_nodes(top_reviews, ".review-text")
top_reviews <- html_text(top_reviews)

user_reviews <- 
  "https://www.rottentomatoes.com/m/coco_2017/reviews?type=user" |> 
  bow() |> 
  scrape()
user_reviews <- html_nodes(user_reviews, ".js-review-text")
user_reviews <- html_text(user_reviews)
```


9. `top_reviews` is a character vector containing the 20 most recent critic reviews (along with some other junk) for Coco, while `user_reviews` is a character vector with the 10 most recent user reviews.

a) Explain how the code below helps clean up both `user_reviews` and `top_reviews` before we start using them.

```{r}
user_reviews <- str_trim(user_reviews)
top_reviews <- str_trim(top_reviews)
```

>> We remove the whitespace from the start and end of the strings in user_review and topreviw

b) Print out the critic reviews where the reviewer mentions "emotion" or "cry".  Think about various forms ("cried", "emotional", etc.)  You may want to turn reviews to all lower case before searching for matches.

```{r}
str_subset(str_to_lower(user_reviews), "cry|cried|emotional|sad|devasted")
```


c) In critic reviews, replace all instances where "Pixar" is used with its full name: "Pixar Animation Studios".

```{r}
str_replace(top_reviews, "Pixar", "Pixar Animation Studios")
```

d) Find out how many times each user uses "I" in their review.  Remember that it could be used as upper or lower case, at the beginning, middle, or end of a sentence, etc.

```{r}
str_count(str_to_lower(user_reviews), "\\b(i)\\b")

str_count(str_to_lower(user_reviews), "[i]")
```

e) Do critics or users have more complex reviews, as measured by average number of commas used?  Be sure your code weeds out commas used in numbers, such as "12,345".

```{r}
mean(str_count(str_to_lower(top_reviews), "[^\\d],"))

mean(str_count(str_to_lower(user_reviews), "[^\\d],"))
```

>> Users have a mean use of 2.2 commas and critics have a mean use of 1.35.


